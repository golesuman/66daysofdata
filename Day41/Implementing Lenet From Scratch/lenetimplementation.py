# -*- coding: utf-8 -*-
"""Lenetimplementation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ly0fgBKK7YOOYcCfmOA-q3-dFJqwTWxS
"""

import numpy as np
import matplotlib.pyplot as plt
import torch
import torchvision
import torch.nn as nn
import torch.nn.functional as F
import torchvision.transforms as transforms

class LeNet(nn.Module):
  def __init__(self):
    super(LeNet, self).__init__()
    # 3 input image channel, 6 output feature maps and 5x5 conv kernel
    self.cn1 = nn.Conv2d(3, 6, 5)
    # 6 input image channel, 16 output feature maps and 5x5 conv kernel
    self.cn2 = nn.Conv2d(6, 16, 5)
    # fully connected layers of size 120, 84 and 10
    self.fc1 = nn.Linear(16 * 5 * 5, 120) # 5*5 is the spatial dimension at this layer
    self.fc2 = nn.Linear(120, 84)
    self.fc3 = nn.Linear(84, 10)

  def forward(self, x):
    x = F.relu(self.cn1(x))
    # Max pooling over a (2, 2) window
    x = F.max_pool2d(x, (2, 2))
    # Convolution with 5x5 kernel
    x = F.relu(self.cn2(x))
    # Max pooling over a (2, 2) window
    x = F.max_pool2d(x, (2, 2))
    # Flatten spatial and depth dimensions into a single vector
    x = x.view(-1, self.flattened_features(x))
    # Fully connected operations
    x = F.relu(self.fc1(x))
    x = F.relu(self.fc2(x))
    x = self.fc3(x)
    return x

  def flattened_features(self, x):
    # all except the first (batch) dimension
    size = x.size()[1:]
    num_feats = 1
    for s in size:
      num_feats *= s
      return num_feats
lenet = LeNet()
print(lenet)

def train(net, trainloader, optim, epoch):
  # initialize loss
  loss_total = 0.0
  for i, data in enumerate(trainloader, 0):
    # get the inputs; data is a list of [inputs, labels]
    # ip refers to the input images, and ground_truth refers to the output classes the images belong to
    ip, ground_truth = data
    # zero the parameter gradients
    optim.zero_grad()
    # forward-pass + backward-pass + optimization -step
    op = net(ip)
    loss = nn.CrossEntropyLoss()(op, ground_truth)
    loss.backward()
    optim.step()
    # update loss
    loss_total += loss.item()
    # print loss statistics
    if (i+1) % 1000 == 0:
    # print at the interval of 1000 mini-batches
      print('[Epoch number : %d, Mini-batches: %5d] loss: %.3f' % (epoch
      + 1, i + 1, loss_total / 200))

def test(net, testloader):
  success = 0
  counter = 0
  with torch.no_grad():
    for data in testloader:
      im, ground_truth = data
      op = net(im)
      _, pred = torch.max(op.data, 1)
      counter += ground_truth.size(0)
      success += (pred == ground_truth).sum().item()
      print('LeNet accuracy on 10000 images from test dataset: %d %%' % (100
      * success / counter))

train_transform = transforms.Compose([transforms.RandomHorizontalFlip(),
transforms.RandomCrop(32, 4),
transforms.ToTensor(),
transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])
trainset = torchvision.datasets.CIFAR10(root='./data', train=True,
download=True, transform=train_transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=8, shuffle=True,
num_workers=1)
test_transform = transforms.Compose([transforms.ToTensor(),
transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

rainset = torchvision.datasets.CIFAR10(root='./data', train=True,
download=True, transform=train_transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=8, shuffle=True,
num_workers=1)
test_transform = transforms.Compose([transforms.ToTensor(),
transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])
testset = torchvision.datasets.CIFAR10(root='./data', train=False,
download=True, transform=test_transform)
testloader = torch.utils.data.DataLoader(testset, batch_size=10000,
shuffle=False, num_workers=2)
# ordering is important
classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']

optim = torch.optim.Adam(lenet.parameters(), lr=0.001)
# training loop over the dataset multiple times
for epoch in range(50):
  train(lenet, trainloader, optim, epoch)
  print()
  test(lenet, testloader)
  print()
print('Finished Training')

d_iter = iter(testloader)
im, ground_truth = d_iter.next()
# print images and ground truth
imageshow(torchvision.utils.make_grid(im[:4]))
print('Label:
', ' '.join('%5s' % classes[ground_truth[j]] for j in range(4)))
# load model
lenet_cached = LeNet()
lenet_cached.load_state_dict(torch.load(model_path))
# model inference
op = lenet_cached(im)
# print predictions
_, pred = torch.max(op, 1)
print('Prediction: ', ' '.join('%5s' % classes[pred[j]] for j in range(4)))